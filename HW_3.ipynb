{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "skilled-algorithm",
   "metadata": {},
   "source": [
    "## **Тема “Обучение с учителем”**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-athletics",
   "metadata": {},
   "source": [
    "**Задание 1**\n",
    "\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instructional-tenant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711226005748496"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "boston = load_boston()\n",
    "feature_names = boston[\"feature_names\"]\n",
    "\n",
    "data = boston[\"data\"]\n",
    "target = boston[\"target\"]\n",
    "\n",
    "X = pd.DataFrame(data, columns = feature_names)\n",
    "y = pd.DataFrame(target, columns = [\"Price\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size  = 0.3, random_state = 42)\n",
    "lr = LinearRegression()\n",
    "\n",
    "#обучение модели\n",
    "lr.fit(X_train, y_train)\n",
    "#предсказание\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "#сопоставление предсказанных и реальных\n",
    "check_test = pd.DataFrame({\n",
    "    'y_test': y_test[\"Price\"],\n",
    "    'y_pred': y_pred.flatten()\n",
    "})\n",
    "\n",
    "check_test[\"Error\"] = check_test[\"y_pred\"]  - check_test[\"y_test\"]\n",
    "\n",
    "#mse1 = (check_test[\"Error\"] ** 2).mean()\n",
    "#mse2 = mean_squared_error(check_test['y_pred'], check_test['y_test'])\n",
    "#mse1 = 21.517444231177 \n",
    "#mse2 = 21.517444231176995\n",
    "\n",
    "(np.abs(check_test[\"Error\"])).mean()\n",
    "#3.162709871457379\n",
    "\n",
    "r2_score(y_test[\"Price\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-toolbox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.648960</td>\n",
       "      <td>5.048960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.495014</td>\n",
       "      <td>4.095014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.411193</td>\n",
       "      <td>1.811193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.403213</td>\n",
       "      <td>2.603213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.855280</td>\n",
       "      <td>2.755280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>17.1</td>\n",
       "      <td>17.403672</td>\n",
       "      <td>0.303672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.5</td>\n",
       "      <td>13.385941</td>\n",
       "      <td>-1.114059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>50.0</td>\n",
       "      <td>39.983425</td>\n",
       "      <td>-10.016575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>14.3</td>\n",
       "      <td>16.682863</td>\n",
       "      <td>2.382863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>12.6</td>\n",
       "      <td>18.285618</td>\n",
       "      <td>5.685618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test     y_pred      Error\n",
       "173    23.6  28.648960   5.048960\n",
       "274    32.4  36.495014   4.095014\n",
       "491    13.6  15.411193   1.811193\n",
       "72     22.8  25.403213   2.603213\n",
       "452    16.1  18.855280   2.755280\n",
       "..      ...        ...        ...\n",
       "441    17.1  17.403672   0.303672\n",
       "23     14.5  13.385941  -1.114059\n",
       "225    50.0  39.983425 -10.016575\n",
       "433    14.3  16.682863   2.382863\n",
       "447    12.6  18.285618   5.685618\n",
       "\n",
       "[152 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-forge",
   "metadata": {},
   "source": [
    "**Задание 2**\n",
    "\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-statement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87472606157312"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, max_depth = 12, random_state = 42)\n",
    "model.fit(X_train, y_train.values[:,0])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2_score(y_test[\"Price\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eight-subscription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>LR y_pred</th>\n",
       "      <th>RF y_pred</th>\n",
       "      <th>LR Error</th>\n",
       "      <th>RF Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.648960</td>\n",
       "      <td>22.806412</td>\n",
       "      <td>5.048960</td>\n",
       "      <td>-0.793588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.495014</td>\n",
       "      <td>31.131464</td>\n",
       "      <td>4.095014</td>\n",
       "      <td>-1.268536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.411193</td>\n",
       "      <td>16.339125</td>\n",
       "      <td>1.811193</td>\n",
       "      <td>2.739125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.403213</td>\n",
       "      <td>23.810726</td>\n",
       "      <td>2.603213</td>\n",
       "      <td>1.010726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.855280</td>\n",
       "      <td>17.139521</td>\n",
       "      <td>2.755280</td>\n",
       "      <td>1.039521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>17.1</td>\n",
       "      <td>17.403672</td>\n",
       "      <td>13.521640</td>\n",
       "      <td>0.303672</td>\n",
       "      <td>-3.578360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.5</td>\n",
       "      <td>13.385941</td>\n",
       "      <td>15.112621</td>\n",
       "      <td>-1.114059</td>\n",
       "      <td>0.612621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>50.0</td>\n",
       "      <td>39.983425</td>\n",
       "      <td>42.808700</td>\n",
       "      <td>-10.016575</td>\n",
       "      <td>-7.191300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>14.3</td>\n",
       "      <td>16.682863</td>\n",
       "      <td>15.586103</td>\n",
       "      <td>2.382863</td>\n",
       "      <td>1.286103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>12.6</td>\n",
       "      <td>18.285618</td>\n",
       "      <td>16.072425</td>\n",
       "      <td>5.685618</td>\n",
       "      <td>3.472425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  LR y_pred  RF y_pred   LR Error  RF Error\n",
       "173    23.6  28.648960  22.806412   5.048960 -0.793588\n",
       "274    32.4  36.495014  31.131464   4.095014 -1.268536\n",
       "491    13.6  15.411193  16.339125   1.811193  2.739125\n",
       "72     22.8  25.403213  23.810726   2.603213  1.010726\n",
       "452    16.1  18.855280  17.139521   2.755280  1.039521\n",
       "..      ...        ...        ...        ...       ...\n",
       "441    17.1  17.403672  13.521640   0.303672 -3.578360\n",
       "23     14.5  13.385941  15.112621  -1.114059  0.612621\n",
       "225    50.0  39.983425  42.808700 -10.016575 -7.191300\n",
       "433    14.3  16.682863  15.586103   2.382863  1.286103\n",
       "447    12.6  18.285618  16.072425   5.685618  3.472425\n",
       "\n",
       "[152 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_test2 = pd.DataFrame({\n",
    "    'y_test': y_test[\"Price\"],\n",
    "    'LR y_pred': check_test[\"y_pred\"], \n",
    "    'RF y_pred': y_pred.flatten(),\n",
    "    'LR Error' : check_test[\"Error\"],\n",
    "    \"RF Error\" : y_pred.flatten() - y_test[\"Price\"]\n",
    "})\n",
    "check_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-colleague",
   "metadata": {},
   "source": [
    "В большинстве случаев RandomForest(случайный лес?) делает более точные предсказания, за счет чего R2_score(коэффициент детерменации) у него значительно выше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-spell",
   "metadata": {},
   "source": [
    "**Задание 3**\n",
    "\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rental-empire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ?RandomForestRegressor\n",
    "# feature_importances_ : ndarray of shape (n_features,)\n",
    "#     The impurity-based feature importances.\n",
    "#     The higher, the more important the feature.\n",
    "#     The importance of a feature is computed as the (normalized)\n",
    "#     total reduction of the criterion brought by that feature.  It is also\n",
    "#     known as the Gini importance.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#график я нашел на https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html \n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.title(\"Значимость признаков\")\n",
    "plt.gca().yaxis.grid()\n",
    "plt.bar(range(X.shape[1]), importances[indices], color = 'Red', align = \"center\")\n",
    "plt.xticks(range(X.shape[1]), feature_names[indices])\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-glucose",
   "metadata": {},
   "source": [
    "Можно сделать вывод, что **LSTAT (% lower status of the population)** и **RM (average number of rooms per dwelling)** признаки самые важные"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
